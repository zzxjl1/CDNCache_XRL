{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = T.device(\"cuda:0\" if T.cuda.is_available() else \"cpu\")\n",
    "ACTIONS= [\"IDLE\", \"L1\", \"L2\", \"L3\"]\n",
    "GB2MB=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DuelingDeepQNetwork(nn.Module):\n",
    "    def __init__(self, alpha, state_dim, action_dim, fc1_dim, fc2_dim):\n",
    "        super(DuelingDeepQNetwork, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(state_dim, fc1_dim)\n",
    "        self.fc2 = nn.Linear(fc1_dim, fc2_dim)\n",
    "        self.V = nn.Linear(fc2_dim, 1)\n",
    "        self.A = nn.Linear(fc2_dim, action_dim)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = T.relu(self.fc1(state))\n",
    "        x = T.relu(self.fc2(x))\n",
    "\n",
    "        V = self.V(x)\n",
    "        A = self.A(x)\n",
    "        Q = V + A - T.mean(A, dim=-1, keepdim=True)\n",
    "\n",
    "        return Q\n",
    "\n",
    "    def save(self, file_path):\n",
    "        T.save(self, file_path)\n",
    "\n",
    "cache_agent = DuelingDeepQNetwork(alpha=1e-3,\n",
    "                              state_dim=15,\n",
    "                              action_dim=len(ACTIONS),\n",
    "                              fc1_dim=64,\n",
    "                              fc2_dim=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CacheAgentDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.generate()\n",
    "\n",
    "\n",
    "    def gen(self,func, num=1000):\n",
    "        for _ in range(num):\n",
    "            obs, label = func()\n",
    "            self.data.append(obs)\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def generate(self):\n",
    "        self.gen(self.cold_start)\n",
    "\n",
    "    def cold_start(self):\n",
    "        obs = {\n",
    "            \"es_load\":random.uniform(0, 0.1),\n",
    "            \"free_storage_size_ratio_L1\":random.uniform(0, 0.1),\n",
    "            \"free_storage_size_ratio_L2\":random.uniform(0.9, 1),\n",
    "            \"free_storage_size_ratio_L3\":random.uniform(0.9, 1),\n",
    "            \"can_L1_fit\":1,\n",
    "            \"can_L2_fit\":1,\n",
    "            \"can_L3_fit\":1,\n",
    "            \"servie_size\":random.uniform(5, 1000)/GB2MB,\n",
    "            \"estimated_fetch_time\":random.uniform(1, 60),\n",
    "            \"is_popular\":0,\n",
    "            \"charm\":round(abs(np.random.standard_normal(1)[0]), 2),\n",
    "            \"service_request_frequency\":random.randint(0, 3),\n",
    "            \"nearby_servers_count\":random.uniform(0, 1),\n",
    "            \"cached_in_nearby_servers\":0,\n",
    "            \"es_request_frequency\":random.uniform(0, 1)\n",
    "        }\n",
    "        return obs, \"L1\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'es_load': 0.0758620689655172, 'free_storage_size_ratio_L1': 1.0, 'free_storage_size_ratio_L2': 1.0, 'free_storage_size_ratio_L3': 1.0, 'can_L1_fit': True, 'can_L2_fit': True, 'can_L3_fit': True, 'service_size': 8.029, 'estimated_fetch_time': 0.1128421757506457, 'is_popular': False, 'charm': 2.2, 'service_request_frequency': 0.0, 'nearby_servers_count': 3, 'cached_in_nearby_servers': False, 'es_request_frequency': 0.001}\n",
      "L1\n",
      "tensor(0.6890, grad_fn=<DivBackward1>)\n",
      "tensor(0.7125, grad_fn=<DivBackward1>)\n",
      "tensor(0.7928, grad_fn=<DivBackward1>)\n",
      "tensor(0.9249, grad_fn=<DivBackward1>)\n",
      "tensor(0.7128, grad_fn=<DivBackward1>)\n",
      "tensor(0.6061, grad_fn=<DivBackward1>)\n",
      "tensor(0.7143, grad_fn=<DivBackward1>)\n",
      "tensor(0.5903, grad_fn=<DivBackward1>)\n",
      "tensor(0.7345, grad_fn=<DivBackward1>)\n",
      "tensor(0.7001, grad_fn=<DivBackward1>)\n",
      "tensor(0.7774, grad_fn=<DivBackward1>)\n",
      "tensor(0.9017, grad_fn=<DivBackward1>)\n",
      "tensor(0.7215, grad_fn=<DivBackward1>)\n",
      "tensor(0.6869, grad_fn=<DivBackward1>)\n",
      "tensor(1.3383, grad_fn=<DivBackward1>)\n",
      "tensor(0.7475, grad_fn=<DivBackward1>)\n",
      "tensor(1.0093, grad_fn=<DivBackward1>)\n",
      "tensor(0.7171, grad_fn=<DivBackward1>)\n",
      "tensor(0.5146, grad_fn=<DivBackward1>)\n",
      "tensor(0.8451, grad_fn=<DivBackward1>)\n",
      "tensor(0.6597, grad_fn=<DivBackward1>)\n",
      "tensor(3.0417, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class SimulatedDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        filepath = \"../../cache_df.csv\"\n",
    "        df = pd.read_csv(filepath)\n",
    "        for i in range(len(df)):\n",
    "            obs = df.iloc[i, 0:-1].to_dict()\n",
    "            label = df.iloc[i, -1]\n",
    "            self.data.append(obs)\n",
    "            self.labels.append(label)\n",
    "        print(self.data[0])\n",
    "        print(self.labels[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        obs = list(self.data[index].values())\n",
    "        label = self.labels[index]\n",
    "        label_index = ACTIONS.index(label)\n",
    "        one_hot = np.zeros(len(ACTIONS))\n",
    "        one_hot[label_index] = 1\n",
    "        return T.tensor(obs).float(), T.tensor(one_hot).float()\n",
    "\n",
    "def train(network, epochs):\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    dataset = SimulatedDataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    optimizer = network.optimizer\n",
    "    for i in range(epochs):\n",
    "        for data, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data)\n",
    "            loss = loss_func(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(loss)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train(cache_agent, 1)\n",
    "    cache_agent.save(\"cache_agent.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cc5292bf5c830798e60369264793d4ad446af4d95064df5045c9e5f7d07eceb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
